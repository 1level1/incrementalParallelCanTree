\section{Introduction - Add in to what this work contributes}

Describe in the following order:
\begin{enumerate}
\item Take a lot from the abstract regarding the proposition of the algorithm.
\item Add the contribution description here: new algo, testing on spark...
\item Apriori and FP-Growth 
\item problem in paralelism in both cases 
\item problem in incremental
\end{enumerate}

Mining of frequent items and association rules is a well known and studied field in Computer Science.
 The algorithms and solutions in this field can be roughly divided into two types - Apriori~\cite{agrawal1994fast} and tree based solutions~\cite{tsay2009fiut,leung2005cantree,tanbeer2009efficient} Each type has benefits and limitations such as simplicity, performance, memory consumptions and scaling. 
%We can also divide the requirements for frequent items mining, into use cases like:
%\begin{enumerate}
%\item Build and mine once.
%\item Build once and mine many different scenarios.
%\item Build and mine with support for incremental updates.
%\end{enumerate}


In this paper, we will describe an approach for dealing with an incrementally updated database, while avoiding candidate generation, and performing a single DB scan.

We will discuss previous related work, describe current technology and review implementation, usage and performance.

\subsubsection{Contribution}
This work contribution is the following:
\begin{enumerate}
\item Noval developed and implemented algorithm for mining fis.
\item Thorough review, experiment and comparison of existing parallel and incremental algorithms for fis mining based on tree based structures.
\end{enumerate}